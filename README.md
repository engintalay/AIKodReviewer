# ğŸ¤– AI Kod Reviewer

YazÄ±lÄ±m projelerinizi analiz eden ve kod hakkÄ±nda sorular sormanÄ±za olanak saÄŸlayan AI destekli bir uygulamadÄ±r.

## âœ¨ Ã–zellikler

- ğŸ’» **Ã‡oklu Dil DesteÄŸi**: Python, JavaScript, TypeScript, Java, PHP, HTML, CSS ve daha fazlasÄ±
- ğŸ§  **Ã‡alÄ±ÅŸmasÄ±**: Mistral 7B (local LMStudio) - kaynak tasarruflu, hÄ±zlÄ±
- ğŸ“š **Kod Ä°ndeksleme**: Tree-sitter AST parsing ile hÄ±zlÄ± ve doÄŸru arama
- ğŸ” **KaynakÃ§a**: Her cevaba hangi dosyadan esinlenildiÄŸini gÃ¶steren referanslar
- ğŸŒ **Web ArayÃ¼zÃ¼**: Streamlit tabanlÄ±, kullanÄ±cÄ± dostu chat interface
- ğŸš€ **API**: FastAPI tabanlÄ± RESTful backend

## ğŸ“‹ Gereksinimler

### DonanÄ±m
- GPU: NVIDIA (CUDA kompatible) veya CPU
- RAM: Minimum 4 GB (8 GB Ã¶nerilir)
- VRAM: T1000 gibi 1.2-4 GB VRAM

### YazÄ±lÄ±m
- Python 3.8+
- LMStudio (http://localhost:8000)
- pip

## ğŸš€ Kurulum

### 1. LMStudio Kurulumu

1. [LMStudio](https://lmstudio.ai/) indirin ve kurun
2. AÅŸaÄŸÄ±daki modeli indirin:
   - **Mistral 7B Instruct v0.3** (GGUF Q4 quantized - ~1.2 GB)
3. LMStudio'da **Local Server** baÅŸlatÄ±n (varsayÄ±lan port: 8000)

### 2. Proje Kurulumu

```bash
# Depoyu klonla
cd /home/engin/projects/AIKodReviewer

# Backend kurulumu
cd backend
pip install -r requirements.txt

# Frontend kurulumu
cd ../frontend
pip install -r requirements.txt
```

### 3. KonfigÃ¼rasyon

`.env` dosyasÄ±nÄ± aÃ§Ä±n ve gerekirse ayarlarÄ± yapÄ±n:

```env
LMSTUDIO_BASE_URL=http://localhost:8000/v1
LMSTUDIO_MODEL=mistral-7b-instruct-v0.3
BACKEND_URL=http://localhost:5000
```

## ğŸƒ Ã‡alÄ±ÅŸtÄ±rma

### Terminal 1: Backend

```bash
cd backend
python main.py
```

Backend `http://localhost:5000` adresinde baÅŸlayacak.

### Terminal 2: Frontend

```bash
cd frontend
streamlit run app.py
```

Frontend `http://localhost:8501` adresinde aÃ§Ä±lacak.

### LMStudio

LMStudio'yu Ã§alÄ±ÅŸtÄ±rÄ±n ve **Local Server** seÃ§eneÄŸini etkinleÅŸtirin (port 8000).

## ğŸ“– KullanÄ±m

1. **Web arayÃ¼zÃ¼nÃ¼ aÃ§**: `http://localhost:8501`
2. **Proje yÃ¼kle**: ZIP dosyasÄ±nÄ± yÃ¼kle veya yerel klasÃ¶r yolunu gir
3. **Analiz et**: Proje otomatik olarak indekslenir
4. **Soru sor**: Chat kutusunda kod hakkÄ±nda sorular sor
5. **Cevap ve referans gÃ¶rÃ¼ntÃ¼le**: AI modeli cevaplar ve kaynakÃ§a gÃ¶sterir

### Ã–rnek Sorular

- "Bu projede main fonksiyonu nerede tanÄ±mlanmÄ±ÅŸ?"
- "DatabaseConnection class'Ä± nasÄ±l kullanÄ±lÄ±yor?"
- "API endpoints'leri nelerdir?"
- "Error handling nasÄ±l yapÄ±lmÄ±ÅŸ?"

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
AIKodReviewer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI uygulamasÄ±
â”‚   â”œâ”€â”€ indexer.py           # Tree-sitter kod indexer
â”‚   â”œâ”€â”€ llm_client.py        # LMStudio API wrapper
â”‚   â”œâ”€â”€ models.py            # Pydantic veri modelleri
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py               # Streamlit arayÃ¼zÃ¼
â”‚   â””â”€â”€ requirements.txt      # Frontend dependencies
â”œâ”€â”€ .env                      # KonfigÃ¼rasyon dosyasÄ±
â””â”€â”€ README.md               # Bu dosya
```

## ğŸ”Œ API Endpoints

### Backend API

#### `POST /upload`
Proje dosyasÄ±nÄ± (ZIP) yÃ¼kle

```bash
curl -X POST -F "file=@project.zip" http://localhost:5000/upload
```

**YanÄ±t:**
```json
{
  "project_id": "abc123def456",
  "status": "success",
  "message": "Proje baÅŸarÄ±yla yÃ¼klendi",
  "file_count": 45
}
```

#### `POST /analyze`
YÃ¼klenen projeyi analiz et

```bash
curl -X POST http://localhost:5000/analyze?project_id=abc123def456
```

#### `POST /query`
Projeye soru sor

```bash
curl -X POST http://localhost:5000/query \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": "abc123def456",
    "question": "Main fonksiyonu nerede?",
    "include_snippets": true
  }'
```

**YanÄ±t:**
```json
{
  "answer": "Main fonksiyonu app.py dosyasÄ±nda 45. satÄ±rda tanÄ±mlanmÄ±ÅŸtÄ±r...",
  "references": [
    {
      "file": "app.py",
      "element": "main",
      "type": "function",
      "lines": [45, 62]
    }
  ],
  "model_used": "mistral-7b-instruct-v0.3",
  "processing_time": 2.34
}
```

#### `GET /health`
Sistem saÄŸlÄ±ÄŸÄ±nÄ± kontrol et

```bash
curl http://localhost:5000/health
```

## ğŸ§  Desteklenen Diller

Tree-sitter aracÄ±lÄ±ÄŸÄ±yla desteklenen diller:

- âœ… Python
- âœ… JavaScript / TypeScript
- âœ… Java
- âœ… PHP
- âœ… HTML
- âœ… CSS
- âœ… C / C++
- âœ… Go
- âœ… Rust
- *ve daha fazlasÄ±...*

## âš™ï¸ GeliÅŸmiÅŸ KonfigÃ¼rasyon

### LMStudio Port'unu DeÄŸiÅŸtirme

`.env` dosyasÄ±nda:
```env
LMSTUDIO_BASE_URL=http://localhost:9000/v1
```

### Backend Port'unu DeÄŸiÅŸtirme

`.env` dosyasÄ±nda:
```env
BACKEND_PORT=5001
```

Sonra:
```bash
python backend/main.py --port 5001
```

### FarklÄ± Model Kullanma

`.env` dosyasÄ±nda:
```env
LMSTUDIO_MODEL=neural-chat-7b-v3-1
```

## ğŸ› Sorun Giderme

### "LMStudio'ya baÄŸlanÄ±lamÄ±yor"
- LMStudio Ã§alÄ±ÅŸÄ±yor mu kontrol et
- Port 8000 kullanÄ±lÄ±yor mu kontrol et
- `.env` dosyasÄ±nda `LMSTUDIO_BASE_URL` kontrolÃ¼

### "Tree-sitter parsing hatasÄ±"
- Tree-sitter kÃ¼tÃ¼phaneleri kurulu mu kontrol et
- `pip install tree-sitter tree-sitter-python ...`

### "Proje iÅŸleme sÃ¼resi uzun"
- BÃ¼yÃ¼k projeler daha fazla zaman alÄ±r
- Model yanÄ±t sÃ¼resi kontrol et (LMStudio ayarlarÄ±)

## ğŸ“Š Performans

- **KÃ¼Ã§Ã¼k projeler** (<1000 dosya): ~2-5 saniye
- **Orta projeler** (1000-5000 dosya): ~5-15 saniye
- **BÃ¼yÃ¼k projeler** (>5000 dosya): ~15-60 saniye
- **Model yanÄ±t sÃ¼resi**: Mistral 7B Q4 ~1-3 saniye (GPU hÄ±zlÄ±, CPU yavaÅŸ)

## ğŸ” GÃ¼venlik Notu

- LMStudio local Ã§alÄ±ÅŸÄ±r, veriler internet'e gitmez
- YÃ¼klenen dosyalar geÃ§ici olarak depolanÄ±r ve iÅŸlem sonrasÄ± silinir
- CORS tÃ¼m origins'e aÃ§Ä±ktÄ±r (development iÃ§in)

## ğŸ“ Lisans

MIT

## ğŸ¤ KatkÄ±dalar

KatkÄ±lar hoÅŸ karÅŸÄ±lanÄ±r! Issues ve Pull Requests aÃ§abilirsiniz.

## ğŸ“§ Ä°letiÅŸim

Sorular ve Ã¶neriler iÃ§in issues aÃ§Ä±nÄ±z.

---

**YapÄ±mcÄ±**: AI Kod Reviewer Team
**Son GÃ¼ncelleme**: 25 Åubat 2026
